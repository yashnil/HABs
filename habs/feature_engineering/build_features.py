#!/usr/bin/env python3
"""
feature_engineering/build_features.py
------------------------------------
Create a 4-D tensor (time, lat, lon, channel) from
root_dataset_filled.nc   â†’   features.zarr

Channels
========
1. MODIS   : chlor_a, Kd_490, nflh, sst
2. ERA-5   : tp, avg_sdswrf, t2m, d2m, u10, v10
3. CMEMS   : so, thetao, uo, vo, zos
4. mask    : binary ocean mask   (1 = ocean / valid pixel, 0 = land or perm-NaN)
5. time    : sin( 2Ï€ DOY âˆ• 366 ),  cos( 2Ï€ DOY âˆ• 366 )

Normalisation
=============
Each science variable is z-scored over **finite** pixels only.
The means / stds are saved to  norm_stats.yml  for later inverse-transform.

Run
~~~
    python feature_engineering/build_features.py
       â€“ the script will create *features.zarr* (~2 GB, chunked) and
         *norm_stats.yml* in the same folder.
"""

from pathlib import Path
import numpy as np
import xarray as xr
import yaml

# â”€â”€ paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = Path("/Users/yashnilmohanty/Desktop/HABs_Research/Processed")
SRC  = ROOT / "root_dataset_filled.nc"
DST  = ROOT / "features.zarr"

# â”€â”€ variables to include â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCI_VARS = [
    # MODIS
    "chlor_a", "Kd_490", "nflh", "sst",
    # ERA-5
    "tp", "avg_sdswrf", "t2m", "d2m", "u10", "v10",
    # CMEMS
    "so", "thetao", "uo", "vo", "zos",
]

# â”€â”€ 1 Â· open source cube (lazy / dask) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print(f"ðŸ”¹ opening {SRC.name} â€¦")
ds = xr.open_dataset(SRC, chunks={"time": 50})   # â‰¤50 frames per dask chunk

# â”€â”€ 2 Â· build static ocean-mask channel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ðŸ”¹ computing ocean mask â€¦")
mask = xr.full_like(ds[SCI_VARS[0]].isel(time=0), 1, dtype="int8")
for var in SCI_VARS:
    mask = mask.where(np.isfinite(ds[var].isel(time=0)), 0)
mask.name = "ocean_mask"
mask.attrs["long_name"] = "static mask (1=ocean, 0=land/permanent-NaN)"

# â”€â”€ 3 Â· z-score normalisation per variable â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ðŸ”¹ normalising variables â€¦")
norm_vars = {}
norm_stats = {}
for v in SCI_VARS:
    dv = ds[v]
    mu = float(dv.mean(dim=("time", "lat", "lon"), skipna=True))
    sd = float(dv.std (dim=("time", "lat", "lon"), skipna=True))
    norm_vars[v] = (dv - mu) / sd
    norm_vars[v].attrs.update({"mean": mu, "std": sd, "normalised": "z"})
    norm_stats[v] = {"mean": mu, "std": sd}
    print(f"   {v:10s} : Î¼={mu:7.3g}   Ïƒ={sd:7.3g}")

# â”€â”€ 4 Â· sin / cos of day-of-year â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ðŸ”¹ generating time sin/cos â€¦")
doy   = ds.time.dt.dayofyear.astype("float32")
angle = 2.0 * np.pi * doy / 366.0
sin_t = xr.DataArray(np.sin(angle), dims="time", coords={"time": ds.time},
                     name="doy_sin")
cos_t = xr.DataArray(np.cos(angle), dims="time", coords={"time": ds.time},
                     name="doy_cos")

# broadcast to (time, lat, lon) by matching an existing 3-D variable
tmpl  = ds[SCI_VARS[0]]                 # any (time,lat,lon) field
sin3  = sin_t.broadcast_like(tmpl)
cos3  = cos_t.broadcast_like(tmpl)

# â”€â”€ 5 Â· assemble into single Dataset & stack channels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ðŸ”¹ stacking into channel dimension â€¦")
all_vars = {**norm_vars, "mask": mask, "doy_sin": sin3, "doy_cos": cos3}
feat_ds  = xr.Dataset(all_vars)
feat_da  = feat_ds.to_array(dim="channel")          # (channel,time,lat,lon)
feat_da  = feat_da.transpose("time", "lat", "lon", "channel")

# â”€â”€ 6 Â· write to Zarr (default compression/chunking) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print(f"ðŸ”¹ writing {DST.name} â€¦")
feat_da.to_dataset(name="features").to_zarr(DST, mode="w")
print("âœ…  features.zarr written")

# â”€â”€ 7 Â· save normalisation stats for later use â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open(ROOT / "norm_stats.yml", "w") as f:
    yaml.safe_dump(norm_stats, f)
print("âœ…  norm_stats.yml written")
